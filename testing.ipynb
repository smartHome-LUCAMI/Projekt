{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import functions_data_processing as fsd\n",
    "from sklearn import svm\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Microwave</th>\n",
       "      <th>Default</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Microwave - Default (combined)</th>\n",
       "      <th>Garage door</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:02:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:03:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 05:04:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 22:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 22:01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 22:02:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 22:03:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 22:04:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Microwave  Default  Ground Truth  \\\n",
       "2016-01-01 05:00:00        0.0      1.0           1.0   \n",
       "2016-01-01 05:01:00        0.0      1.0           1.0   \n",
       "2016-01-01 05:02:00        0.0      1.0           1.0   \n",
       "2016-01-01 05:03:00        0.0      1.0           1.0   \n",
       "2016-01-01 05:04:00        0.0      1.0           1.0   \n",
       "...                        ...      ...           ...   \n",
       "2016-01-01 22:00:00        0.0      1.0           1.0   \n",
       "2016-01-01 22:01:00        0.0      1.0           1.0   \n",
       "2016-01-01 22:02:00        0.0      1.0           1.0   \n",
       "2016-01-01 22:03:00        0.0      1.0           1.0   \n",
       "2016-01-01 22:04:00        0.0      1.0           1.0   \n",
       "\n",
       "                    Microwave - Default (combined)  Garage door  \n",
       "2016-01-01 05:00:00                             01          0.0  \n",
       "2016-01-01 05:01:00                             01          0.0  \n",
       "2016-01-01 05:02:00                             01          0.0  \n",
       "2016-01-01 05:03:00                             01          0.0  \n",
       "2016-01-01 05:04:00                             01          0.0  \n",
       "...                                            ...          ...  \n",
       "2016-01-01 22:00:00                             01          0.0  \n",
       "2016-01-01 22:01:00                             01          0.0  \n",
       "2016-01-01 22:02:00                             01          0.0  \n",
       "2016-01-01 22:03:00                             01          0.0  \n",
       "2016-01-01 22:04:00                             01          0.0  \n",
       "\n",
       "[1025 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell changes the values of the df.csv file in order for the absent state to have a value of 0 instead of 0.1 and the present state to have a value of 1 instead of 0.9\n",
    "# Furthermore it adds a new column in which we have both values of Microwave and Default combined\n",
    "\n",
    "df_imported = pd.read_csv('df.csv', index_col=0)\n",
    "df_imported = df_imported\n",
    "df_imported.index = pd.to_datetime(df_imported.index)\n",
    "df = pd.DataFrame()\n",
    "df['Microwave'] = df_imported['Microwave']\n",
    "df['Default'] = df_imported['Default']\n",
    "df['Ground Truth'] = df_imported['Ground Truth']\n",
    "df['Microwave - Default (combined)'] = 'temporary'\n",
    "df['Garage door'] = df_imported['Garage door']\n",
    "\n",
    "df =df.mask(df==0.9, 1)\n",
    "df =df.mask(df==0.1, 0)\n",
    "\n",
    "mask1 = (df['Microwave']==1.0) & (df['Default']==1.0)\n",
    "mask2 = (df['Microwave']==0.0) & (df['Default']==1.0)\n",
    "mask3 = (df['Microwave']==0.0) & (df['Default']==0.0)\n",
    "mask4 = (df['Microwave']==1.0) & (df['Default']==0.0)\n",
    "\n",
    "df['Microwave - Default (combined)'] = ''\n",
    "df['Microwave - Default (combined)'] = df['Microwave - Default (combined)'].mask(mask1, '11')\n",
    "df['Microwave - Default (combined)'] = df['Microwave - Default (combined)'].mask(mask2, '01')\n",
    "df['Microwave - Default (combined)'] = df['Microwave - Default (combined)'].mask(mask3, '00')\n",
    "df['Microwave - Default (combined)'] = df['Microwave - Default (combined)'].mask(mask4, '10')\n",
    "df.iloc[:1025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that selects a section of the data frame based on a starting date and interval\n",
    "\n",
    "def interval_model(data_frame, starting_date, interval):\n",
    "    \n",
    "    s_date = pd.to_datetime(starting_date, format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    data_frame = data_frame.loc[s_date : s_date + interval]\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-02-01 05:00:00    01\n",
       "2016-02-01 05:01:00    01\n",
       "2016-02-01 05:02:00    01\n",
       "2016-02-01 05:03:00    01\n",
       "2016-02-01 05:04:00    01\n",
       "                       ..\n",
       "2016-02-08 04:56:00    01\n",
       "2016-02-08 04:57:00    01\n",
       "2016-02-08 04:58:00    01\n",
       "2016-02-08 04:59:00    01\n",
       "2016-02-08 05:00:00    01\n",
       "Name: Microwave - Default (combined), Length: 10081, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of using the function interval_model defined above\n",
    "df_model = df['Microwave - Default (combined)']\n",
    "\n",
    "df_model = interval_model(data_frame= df_model, starting_date='2016-02-01 05:00:00', interval=datetime.timedelta(days=7))\n",
    "\n",
    "df_model.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following cells are used just for testing and getting a feel for how the HMM model is deployed and can be ignored \n",
    "\n",
    "\n",
    "\n",
    "''' A function that returns a list of lists where each list has 4 values based on the counted values of the ostates in the status input variable'''\n",
    "def sequence2counts(status, ostates2id):\n",
    "    ans = []\n",
    "    for word, idx in ostates2id.items():\n",
    "       \n",
    "        count = status.count(word)\n",
    "        ans.append(count)\n",
    "    return ans\n",
    "\n",
    "\n",
    "# Smart home situation states: hidden state\n",
    "h_states = ['absent', 'present'] # not at home, at home\n",
    "id2hstates = dict(zip(range(len(h_states)), h_states)) # Dict from numbers to words\n",
    "\n",
    "# Initial distribution of hidden states\n",
    "start_probs = np.array([0.5, 0.5])\n",
    "\n",
    "# microwave and GT: observable states: \n",
    "# Pos 1: Default $Df$\n",
    "# Pos 2: Microvave on off\n",
    "o_states = ['00', '01', '10', '11']  \n",
    "id2ostates = dict(zip(o_states, range(len(o_states))))\n",
    "\n",
    "# Transition probs from hidden to observable states\n",
    "emission_probs = np.array([[0.25, 0.1, 0.4, 0.25],\n",
    "                           [0.2, 0.5, 0.1, 0.2]])\n",
    "\n",
    "# Transition matrix of hidden states\n",
    "trans_mat = np.array([[0.5, 0.5], [0.5, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lst = [0] *7*24\n",
    "for i in range(1,7*24,1):\n",
    "    lst[i-1] = df_model.tolist()[((i-1)*60):(i*60)]\n",
    "   \n",
    "    \n",
    "lst[167] = df_model.tolist()[(167*60):(168*60)]\n",
    "\n",
    "print(len(lst[167]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    }
   ],
   "source": [
    "observations = lst\n",
    "\n",
    "\n",
    "# Format observations\n",
    "X = []\n",
    "for status in observations:\n",
    "    row = sequence2counts(status, id2ostates)\n",
    "    X.append(row)\n",
    "data = np.array(X, dtype=int)\n",
    "\n",
    "\n",
    "n_trials = len(observations[0])\n",
    "\n",
    "\n",
    "# Build the model\n",
    "# Set up model:\n",
    "model = hmm.MultinomialHMM(n_components=len(h_states),\n",
    "        n_trials=n_trials,\n",
    "        init_params='')\n",
    "\n",
    "model.n_features = len(o_states)\n",
    "\n",
    "model.startprob_ = start_probs\n",
    "model.transmat_ = trans_mat\n",
    "model.emissionprob_ = emission_probs\n",
    "\n",
    "\n",
    "\n",
    "model.fit(data)\n",
    "\n",
    "# Estimate state\n",
    "logprob, state_ests = model.decode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated states\n",
      "['present', 'present', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'absent', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present', 'present']\n",
      "------------------------------------\n",
      "Learned emission probs:\n",
      "[[0.99805195 0.         0.00194805 0.        ]\n",
      " [0.         0.99468864 0.         0.00531136]]\n",
      "------------------------------------\n",
      "Learned transition matrix:\n",
      "[[0.90909091 0.09090909]\n",
      " [0.07777778 0.92222222]]\n"
     ]
    }
   ],
   "source": [
    "# Print states\n",
    "print(\"Estimated states\")\n",
    "print([id2hstates[x] for x in state_ests])\n",
    "print('------------------------------------')\n",
    "print(\"Learned emission probs:\")\n",
    "print(model.emissionprob_)\n",
    "print('------------------------------------')\n",
    "print(\"Learned transition matrix:\")\n",
    "print(model.transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_original = interval_model(data_frame= df['Ground Truth'], starting_date='2016-01-01 05:00:00', interval=datetime.timedelta(days=7))\n",
    "\n",
    "\n",
    "\n",
    "y_true = y_true_original\n",
    "ss = ShuffleSplit(n_splits=25, test_size=0.3)\n",
    "\n",
    "\n",
    "list_true = [0] *7*24\n",
    "for i in range(1,7*24,1):\n",
    "    list_true[i-1] = y_true.tolist()[((i-1)*60):(i*60)]\n",
    "   \n",
    "    \n",
    "list_true[167] = y_true.tolist()[(167*60):(168*60)]\n",
    "\n",
    "l = []\n",
    "for status in list_true:\n",
    "    row = sequence2counts(status, dict(zip(range(len([0,1])), [0,1])))\n",
    "    l.append(row)\n",
    "y_true = np.array(l, dtype=int)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(y_true.shape[0]):\n",
    "    if y_true[i,0]>=y_true[i,1]:\n",
    "        y_true[i]=0\n",
    "    else:\n",
    "        y_true[i]=1\n",
    "\n",
    "\n",
    "\n",
    "y_true = y_true[:,0]\n",
    "\n",
    "y_pred_proba_all = np.zeros(len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics discussed:\n",
      "['cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog']\n",
      "Learned emission probs:\n",
      "[[2.57129200e-01 2.86190571e-02 4.28541642e-01 2.85710101e-01]\n",
      " [1.33352852e-01 7.33292496e-01 2.67548571e-05 1.33327897e-01]]\n",
      "Learned transition matrix:\n",
      "[[0.71429762 0.28570238]\n",
      " [0.50007593 0.49992407]]\n",
      "\n",
      "New Model\n",
      "Topics discussed:\n",
      "['dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat']\n",
      "Learned emission probs:\n",
      "[[1.33343271e-01 7.33312149e-01 1.94587996e-05 1.33325122e-01]\n",
      " [2.57131358e-01 2.86217251e-02 4.28538025e-01 2.85708892e-01]]\n",
      "Learned transition matrix:\n",
      "[[0.49989688 0.50010312]\n",
      " [0.28569778 0.71430222]]\n"
     ]
    }
   ],
   "source": [
    "# For this example, we will model the stages of a conversation,\n",
    "# where each sentence is \"generated\" with an underlying topic, \"cat\" or \"dog\"\n",
    "states = [\"cat\", \"dog\"]\n",
    "id2topic = dict(zip(range(len(states)), states))\n",
    "# we are more likely to talk about cats first\n",
    "start_probs = np.array([0.6, 0.4])\n",
    "\n",
    "# For each topic, the probability of saying certain words can be modeled by\n",
    "# a distribution over vocabulary associated with the categories\n",
    "\n",
    "vocabulary = [\"tail\", \"fetch\", \"mouse\", \"food\"]\n",
    "# if the topic is \"cat\", we are more likely to talk about \"mouse\"\n",
    "# if the topic is \"dog\", we are more likely to talk about \"fetch\"\n",
    "emission_probs = np.array([[0.25, 0.1, 0.4, 0.25],\n",
    "                           [0.2, 0.5, 0.1, 0.2]])\n",
    "\n",
    "# Also assume it's more likely to stay in a state than transition to the other\n",
    "trans_mat = np.array([[0.8, 0.2], [0.2, 0.8]])\n",
    "\n",
    "\n",
    "# Pretend that every sentence we speak only has a total of 5 words,\n",
    "# i.e. we independently utter a word from the vocabulary 5 times per sentence\n",
    "# we observe the following bag of words (BoW) for 8 sentences:\n",
    "observations = [[\"tail\", \"mouse\", \"mouse\", \"food\", \"mouse\"],\n",
    "        [\"food\", \"mouse\", \"mouse\", \"food\", \"mouse\"],\n",
    "        [\"tail\", \"mouse\", \"mouse\", \"tail\", \"mouse\"],\n",
    "        [\"food\", \"mouse\", \"food\", \"food\", \"tail\"],\n",
    "        [\"tail\", \"fetch\", \"mouse\", \"food\", \"tail\"],\n",
    "        [\"tail\", \"fetch\", \"fetch\", \"food\", \"fetch\"],\n",
    "        [\"fetch\", \"fetch\", \"fetch\", \"food\", \"tail\"],\n",
    "        [\"food\", \"mouse\", \"food\", \"food\", \"tail\"],\n",
    "        [\"tail\", \"mouse\", \"mouse\", \"tail\", \"mouse\"],\n",
    "        [\"fetch\", \"fetch\", \"fetch\", \"fetch\", \"fetch\"]]\n",
    "\n",
    "# Convert \"sentences\" to numbers:\n",
    "vocab2id = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "def sentence2counts(sentence):\n",
    "    ans = []\n",
    "    for word, idx in vocab2id.items():\n",
    "        count = sentence.count(word)\n",
    "        ans.append(count)\n",
    "    return ans\n",
    "\n",
    "X = []\n",
    "for sentence in observations:\n",
    "    row = sentence2counts(sentence)\n",
    "    X.append(row)\n",
    "\n",
    "data = np.array(X, dtype=int)\n",
    "\n",
    "# pretend this is repeated, so we have more data to learn from:\n",
    "lengths = [len(X)]*5\n",
    "sequences = np.tile(data, (5,1))\n",
    "\n",
    "\n",
    "# Set up model:\n",
    "model = hmm.MultinomialHMM(n_components=len(states),\n",
    "        n_trials=len(observations[0]),\n",
    "        n_iter=50,\n",
    "        init_params='')\n",
    "\n",
    "model.n_features = len(vocabulary)\n",
    "model.startprob_ = start_probs\n",
    "model.transmat_ = trans_mat\n",
    "model.emissionprob_ = emission_probs\n",
    "model.fit(sequences, lengths)\n",
    "logprob, received = model.decode(sequences)\n",
    "\n",
    "print(\"Topics discussed:\")\n",
    "print([id2topic[x] for x in received])\n",
    "\n",
    "print(\"Learned emission probs:\")\n",
    "print(model.emissionprob_)\n",
    "\n",
    "print(\"Learned transition matrix:\")\n",
    "print(model.transmat_)\n",
    "\n",
    "# Try to reset and refit:\n",
    "new_model = hmm.MultinomialHMM(n_components=len(states),\n",
    "        n_trials=len(observations[0]),\n",
    "        n_iter=50, init_params='ste')\n",
    "\n",
    "new_model.fit(sequences, lengths)\n",
    "logprob, received = new_model.decode(sequences)\n",
    "\n",
    "print(\"\\nNew Model\")\n",
    "print(\"Topics discussed:\")\n",
    "print([id2topic[x] for x in received])\n",
    "\n",
    "print(\"Learned emission probs:\")\n",
    "print(new_model.emissionprob_)\n",
    "\n",
    "print(\"Learned transition matrix:\")\n",
    "print(new_model.transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
